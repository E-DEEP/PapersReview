# GAN: Generative Adversarial Network

## Abstract)
+ 새로운 프레임워크 gan을 제안한다. 

  + 동시에 두 가지 모델을 학습한다.
  + 데이터 분포를 캡쳐하는 generative model G와 샘플이 학습 데이터로부터 온 것인지 판별하는 Discriminal model D로
이루어져 있다. 
  + 이 프레임워크는 각각 생성자G와 판별자D로  구분된다.


## Introduction)

+ 기존 모델의 어려움
  + 그 전까지 Deep generative model은 확률적 계산의 추정이 어렵고,  임팩트가 적다는 어려움을 가지고 있었다.
  + 이러한 어려움들을 회피하는 새로운 생성 모델을 제안한다.

+ 새로운 프레임워크에서 생성자와 판별자가 적대적으로 싸운다.
  + 판별자는 샘플이 모델의 분포에서 온 것인지, 데이터의 분포에서 온 것인지 결정하는 것을 학습한다. 
  + Ex. 위조 지폐

> 생성자: 위조 지폐를 만들고. 발견되지 않도록 함
> > 판별자: 위조 지폐를 찾아내고자 함

> > > 위조 지폐가 진짜 지폐로부터 구분이 안 될 때까지 두 개의 팀이 방법을 모두 증진시킨다.

  + 생성 모델이 다층레이어 퍼셉트론을 통해 랜덤 노이즈를 통과하면서 샘플을 생성한다. 
  + 역전파와 드롭아웃 알고리즘을 통해 두 개의 모델을 학습한다. 


## Adversarial Nets)
+ Adversarial 모델링 프레임워크
  + Adversarial 모델링 프레임워크는 모델이 다층레이어 퍼셉트론일 때 가장 간단하게 적용할 수 있다. 
  + 데이터 x에 대한 생성자의 분포 Pg를 학습하기 위해, 입력 노이즈 변수 Pz에 prior를 정의하고, 데이터 공간을 맵핑한다. 이것이 G이다.
  + G는 파라미터로 theta g를 가진 다층레이어 퍼셉트론에 의해 표현되는 미분가능한 함수이다. 

+ Multi-layer perceptron D
  + 두 번째로 단일 스칼라를 출력하는 다층레이어 퍼셉트론 D를 정의한다. 
  + 데이터가 Pg 보다는 x로부터 왔다는 확률을 의미한다. 
  + 학습 예시들과 생성자로부터 샘플, 모두에 맞는 라벨을 할당하는 확률 분포를 최대화하기 위해서 D를 학습한다. 

+ log(1-D(G(z)))를 최소화한다. 
  + G가 logD(G(z))를 최대화하도록 학습시킬 수 있다. 
  + k스텝동안 D를 최적화하고 1스텝동안 G를 최적화하는 것을 반복한다. 
  + D는 최적의 솔루션에 가까워진다.이는 마코브 체인의 샘플을 유지하는 것과 비슷하다.

+ 이는 곧 플레이어가 두 명인 G, D의 minmax game과 같다.



## Theoretical Results)
+ Pg=Pdata
  + 주어진 생성자 G를 위한 최적의 판별자 D를 고려한다. 
  + G가 고정되었을 때, 최적의 판별자 D는 Pdata/(Pdata+Pg)이다.(증명된 최대값 공식을 사용한다.)
(증명 - 논문자료참조)
  + 가상의 학습 기준 C(G)의 글로벌 최저점에 도달하는 것은 Pg=Pdata일 때와 같다. 해당 시점에서 C는 -log(4)이다.

+ Convergence of Algorithm 1
  + G와 D가 충분한 용량을 갖고 있을 때, 판별자는 주어진 G에 대해 최적점에 도달할 수 있고 Pg도 향상된 기준에 대해 업데이트 될 수 있으며 Pg는 Pdata로 수렴된다. 
  + Adversarial nets는 G 를 통해 제한된 Pg 분포 계열을 나타내고, 
  + G를 정의하기 위해 다층레이어 퍼셉트론을 사용하여 파라미터 공간에 다층 critical points를 도입할 수 있다. 
  + 우수한 성능은 합리적인 모델이라는 것을 제안한다.
  
  
  
