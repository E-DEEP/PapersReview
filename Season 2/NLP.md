# Natural Language Processing 논문 리스트(5개)

## 구재원



## 김연수

- GPT3 : Language Models are Few-Shot Learners (https://arxiv.org/abs/2005.14165)
- BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension (https://arxiv.org/abs/1910.13461)
- ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators (https://openreview.net/forum?id=r1xMH1BtvB)
- Big Bird: Transformers for Longer Sequences (https://arxiv.org/abs/2007.14062)
- T5 : Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (https://arxiv.org/abs/1910.10683)

## 류정현



## 백서인
1. ELMo: Deep contextualized word representations [paper](https://arxiv.org/pdf/1802.05365.pdf)
2. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations [paper](https://arxiv.org/pdf/1909.11942.pdf)
3. XLNet: Generalized Autoregressive Pretraining for Language Understanding [paper](https://arxiv.org/pdf/1906.08237.pdf)
4. GPT-2: Language Models are Unsupervised Multitask Learners [paper](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf)
5. GPT-3: Language Models are Few-Shot Learners [paper](https://arxiv.org/pdf/2005.14165v4.pdf)


## 신한이


## 이유진



## 전세희



## 한지수


# Natural Language Processing Github 리스트(5개)



## 구재원



## 김연수

1. BERT [Link](https://github.com/google-research/bert)
2. GPT2 [Link1-huggingface](https://github.com/huggingface/transformers/tree/master/src/transformers/models/gpt2) || [Link2](https://github.com/ConnorJL/GPT2) // GPT3는 비공식도 별로 없어서, 찾을 수 있다면 GPT3 하고싶네요
3. BART [Link-huggingface](https://github.com/huggingface/transformers/tree/1c06240e1b3477728129bb58e7b6c7734bb5074e/src/transformers/models/bart)
4. Transformer [Link1-huggingface](https://github.com/huggingface/transformers/tree/master/src/transformers) || [Link2](https://github.com/Kyubyong/transformer)
5. T5 [Link1](https://github.com/google-research/text-to-text-transfer-transformer) || [Link2-huggingface](https://github.com/huggingface/transformers/tree/master/src/transformers/models/t5)

## 류정현



## 백서인
1. ELMo: https://github.com/allenai/bilm-tf
2. ALBERT: https://github.com/google-research/albert
3. XLNet: https://github.com/zihangdai/xlnet
4. GPT-2: https://github.com/openai/gpt-2 , https://github.com/graykode/gpt-2-Pytorch 
5. GPT-3: https://github.com/openai/gpt-3 (코드는 없음)


## 신한이


## 이유진



## 전세희



## 한지수

