# Computer vision 논문 리스트(5개)

## 구재원
1. DETR: End-to-End Object Detection with Transformers, Facebook AI [paper](https://arxiv.org/pdf/2005.12872.pdf)
2. A Critical Analysis of Self-Supervision, or What We Can Learn From a Single Image, 2020 [paper](https://arxiv.org/pdf/1904.13132.pdf)
3. A Simple Framework for Contrastive Learning of Visual Representations, 2019 [paper](https://arxiv.org/pdf/2002.05709.pdf)
4. Learning the Predictability of the Future, 2021 [paper](https://arxiv.org/pdf/2101.01600.pdf)
5. MixMatch: A Holistic Approach to Semi-Supervised Learning, 2019 [paper](https://arxiv.org/pdf/1905.02249.pdf)
 

## 김연수

- ViT : An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale (https://arxiv.org/abs/2010.11929v1)
- DETR : End-to-End Object Detection with Transformers (https://arxiv.org/abs/2005.12872)
- StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery (https://arxiv.org/abs/2103.01209)
- Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation (https://arxiv.org/abs/1901.02985)
- StyleGAN2 : Analyzing and Improving the Image Quality of StyleGAN (https://arxiv.org/abs/1912.04958)

## 류정현
1. Mask R-CNN (https://arxiv.org/abs/1703.06870)
2. U-Net (https://arxiv.org/abs/1505.04597)
3. RepVGG (https://arxiv.org/abs/2101.03697)
4. DCGAN (https://arxiv.org/abs/1511.06434)
5. EfficientNet (https://arxiv.org/abs/1905.11946)


## 백서인
1. StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks [paper](https://arxiv.org/pdf/1812.04948v3.pdf)
2. StyleGAN2: Analyzing and Improving the Image Quality of StyleGAN [paper](https://arxiv.org/pdf/1912.04958v2.pdf)
3. YOLOv4: Optimal Speed and Accuracy of Object Detection [paper](https://arxiv.org/abs/2004.10934)
4. EfficientNet-L2: Meta Pseudo Labels [paper](https://arxiv.org/pdf/2003.10580v4.pdf)
5. SSD: Single Shot MultiBox Detector [paper](https://arxiv.org/pdf/1512.02325.pdf)


## 신한이


## 이유정
1. <CVPR2020 - Frequency domain > 	Learning in the Frequency Domain  https://arxiv.org/abs/2002.12416
2. <CVPR2020 - Contrastive estimation> Flow Contrastive Estimation of Energy-Based Models / https://arxiv.org/pdf/1912.00589.pdf
3. <CVPR2020 - segmentation> 	F-BRS: Rethinking Backpropagating Refinement for Interactive Segmentation  https://arxiv.org/abs/2001.10331
4. <CVPR2020 - F> FDA: Fourier Domain Adaptation for Semantic Segmentation  http://vladlen.info/papers/MSeg.pdf
5. <CVPR2020 - domain adaptation> Unsupervised Intra-Domain Adaptation for Semantic Segmentation Through Self-Supervision https://arxiv.org/abs/2004.07703



## 전세희

1. ViT : [link](https://arxiv.org/abs/2010.11929v1)
2. StarGAN : [link](https://github.com/yunjey/stargan)
3. RELATION NET : [link](https://openaccess.thecvf.com/content_cvpr_2018/papers/Sung_Learning_to_Compare_CVPR_2018_paper.pdf)
4. semi-supervised ProtoNet : [link](https://openreview.net/pdf?id=HJcSzz-CZ)
5. Swin Transformer : [link](https://arxiv.org/pdf/2103.14030.pdf)


## 한지수
1. MixMatch
2. ReMixMatch: Semi-Supervised Learning with Distribution Alignment and Augmentation Anchoring [link](https://arxiv.org/pdf/1911.09785.pdf)
3. FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidency  [link](https://arxiv.org/pdf/2001.07685.pdf)
4. Feature Pyramid Networks for Object Detection [link](https://arxiv.org/abs/1612.03144)
5. Mask R-CNN [link](https://arxiv.org/pdf/1703.06870.pdf)




# Computer vision Github 리스트(5개)



## 구재원
1. DETR: [link](https://github.com/facebookresearch/detr)
2. Detectron2 [link](https://github.com/facebookresearch/detectron2)
3. StarGAN [link](https://github.com/yunjey/stargan)
4. SinGAN [link](https://github.com/tamarott/SinGAN)
5. U-GAT-IT [link](https://github.com/znxlwm/UGATIT-pytorch)


## 김연수
1. DETR -> 재원님이랑 중복이라서 전 링크 패스할게요!
2. StyleGAN2 (https://github.com/NVlabs/stylegan2) // Original StyleGAN도 좋아용
3. StyleCLIP (https://github.com/orpatashnik/StyleCLIP)
4. YOLO : [A minimal PyTorch implementation of YOLOv3](https://github.com/eriklindernoren/PyTorch-YOLOv3) 공식은 아닙니다
5. Pix2Pix (https://github.com/phillipi/pix2pix)


## 류정현



## 백서인
1. StyleGAN: https://github.com/NVlabs/stylegan
2. StyleGAN2: https://github.com/NVlabs/stylegan2
3. YOLOv4: https://github.com/pjreddie/darknet
4. EfficientNet-L2: https://github.com/google-research/google-research/tree/master/meta_pseudo_labels
5. SSD: https://github.com/amdegroot/ssd.pytorch (공식은 아님)


## 신한이


## 이유



## 전세희
1. ViT : [link](https://github.com/google-research/vision_transformer)
2. yolov1 : [link](https://github.com/pjreddie/darknet/wiki/YOLO:-Real-Time-Object-Detection)
3. StarGAN : [link](https://github.com/yunjey/stargan)
4. HRNet : [link](https://github.com/HRNet/HRNet-Semantic-Segmentation)
5. RelationNet2 : [link](https://github.com/microsoft/RelationNet2)




## 한지수

1. MixMatch
2. ReMixMatch [Github](https://github.com/google-research/remixmatch)
3. FixMatch [Github](https://github.com/google-research/fixmatch)
4. FPN [Github](https://github.com/facebookresearch/detectron)
5. Mask R-CNN [Github](https://github.com/facebookresearch/Detectron)

